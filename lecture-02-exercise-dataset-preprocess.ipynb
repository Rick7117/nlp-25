{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17c18ef3-6f1f-4bef-b581-ac7f210cbf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import spacy\n",
    "import random\n",
    "import convokit\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from nltk import ngrams\n",
    "from collections import defaultdict\n",
    "from convokit import Corpus, download\n",
    "from spacy.tokenizer import Tokenizer\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e706e983-ae37-4ec4-8c82-b95978133ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 convokit datasets\n"
     ]
    }
   ],
   "source": [
    "corpus_names = [\n",
    "    \"chromium-corpus\",\n",
    "    \"conversations-gone-awry-cmv-corpus\",\n",
    "    \"conversations-gone-awry-corpus\",\n",
    "    \"deli-corpus\",\n",
    "    \"diplomacy-corpus\",\n",
    "    \"friends-corpus\",\n",
    "    \"fomc-corpus\",\n",
    "    \"fora-corpus\",\n",
    "    \"gap-corpus\",\n",
    "    \"iq2-corpus\",\n",
    "    \"movie-corpus\",\n",
    "    \"npr-2p-corpus\",\n",
    "    \"parliament-corpus\",\n",
    "    \"persuasionforgood-corpus\",\n",
    "    \"reddit-coarse-discourse-corpus\",\n",
    "    \"reddit-corpus\",\n",
    "    \"reddit-corpus-small\",\n",
    "    \"spolin-corpus\",\n",
    "    \"stack-exchange-politeness-corpus\",\n",
    "    \"supreme-corpus\",\n",
    "    \"switchboard-corpus\",\n",
    "    \"switchboard-processed-corpus\",\n",
    "    \"tennis-corpus\",\n",
    "    \"wiki-corpus\",\n",
    "    \"wiki-politeness-annotated\",\n",
    "    \"wikiconv-corpus\",\n",
    "    \"wikipedia-politeness-corpus\",\n",
    "    \"winning-args-corpus\",\n",
    "    \"wiki-articles-for-deletion-corpus\",\n",
    "    \"casino-corpus\",\n",
    "    \"wiki-sampled-en-corpus\",\n",
    "    \"wiki-sampled-zh-corpus\"]\n",
    "print(f'{len(corpus_names)} convokit datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2385ccd7-1ec4-43eb-bb2d-aae62232fd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"tagger\", \"parser\", \"ner\"])\n",
    "raw_text_file = 'datasets/convokit/convokit-all-raw-text.txt'\n",
    "raw_text_vocab = 'datasets/convokit/convokit-all-raw-vocab.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb89e1b-cdd7-4998-bc6b-34d51d010e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = defaultdict(int)\n",
    "with open('datasets/convokit/convokit-all-raw-text.txt', 'r') as raw_text_f:\n",
    "    texts = raw_text_f.readlines()\n",
    "    docs = nlp.tokenizer.pipe(texts)\n",
    "    count = 0\n",
    "    with open(raw_text_toknenized, 'w') as raw_text_ff:\n",
    "        for doc in tqdm(docs):\n",
    "            trimed = []\n",
    "            for token in doc:\n",
    "                item = token.text.strip()\n",
    "                if len(item) != 0:\n",
    "                    trimed.append(item)\n",
    "                    vocab[item] += 1\n",
    "sorted_vocab = sorted(vocab.items(), key=lambda item: item[1], reverse=True)\n",
    "print(len(sorted_vocab))\n",
    "print(len(sorted_vocab) - len([_ for _ in sorted_vocab if _[1] == 1]))\n",
    "print(len(sorted_vocab) - len([_ for _ in sorted_vocab if _[1] <= 2]))\n",
    "print(len(sorted_vocab) - len([_ for _ in sorted_vocab if _[1] <= 3]))\n",
    "print(len(sorted_vocab) - len([_ for _ in sorted_vocab if _[1] <= 4]))\n",
    "print(len(sorted_vocab) - len([_ for _ in sorted_vocab if _[1] <= 5]))\n",
    "print(len(sorted_vocab) - len([_ for _ in sorted_vocab if _[1] <= 20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "981f2e7c-27a5-4670-aaf0-27ee49cfd4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103947\n"
     ]
    }
   ],
   "source": [
    "less_freq_vocab = {_[0]:\"UNK\" for _ in sorted_vocab if _[1] <=30}\n",
    "print(len(sorted_vocab) - len(less_freq_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "52dd2734-d561-4c1d-86c7-d4a08875b16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "36909120it [28:05, 21893.92it/s]\n"
     ]
    }
   ],
   "source": [
    "train_file = 'datasets/convokit/convokit-all-train.txt'\n",
    "valid_file = 'datasets/convokit/convokit-all-valid.txt'\n",
    "test_file = 'datasets/convokit/convokit-all-test.txt'\n",
    "vocab_input_file = \"datasets/convokit/convokit-all-vocab.json\"\n",
    "\n",
    "random.seed(17)\n",
    "vocab = defaultdict(int)\n",
    "with open(train_file, 'w') as train_out, open(valid_file, 'w') as valid_out, open(test_file, 'w') as test_out:\n",
    "    with open('datasets/convokit/convokit-all-raw-text.txt', 'r') as infile:\n",
    "        texts = infile.readlines()\n",
    "        docs = nlp.tokenizer.pipe(texts)\n",
    "        count = 0\n",
    "        for doc in tqdm(docs):\n",
    "            effective_tokens = []\n",
    "            for token in doc:\n",
    "                item = token.text.strip()\n",
    "                if len(item) != 0:\n",
    "                    if item in less_freq_vocab:\n",
    "                        effective_tokens.append(less_freq_vocab[item])\n",
    "                    else:\n",
    "                        effective_tokens.append(item)\n",
    "                        vocab[item] += 1\n",
    "            trimed_sent = \" \".join(effective_tokens) + '\\n'\n",
    "            rand = random.random()\n",
    "            if rand < 0.98:  # 98 % probability for train\n",
    "                train_out.write(trimed_sent)\n",
    "            elif rand < 0.99:  # 1 % probability for valid\n",
    "                valid_out.write(trimed_sent)\n",
    "            else:  # 1 % probability for test\n",
    "                test_out.write(trimed_sent)\n",
    "\n",
    "sorted_vocab = sorted(vocab.items(), key=lambda item: item[1], reverse=True)\n",
    "with open(vocab_input_file, \"w\") as vocab_file:\n",
    "    for word,count in sorted_vocab:\n",
    "        json.dump({word:count}, vocab_file)\n",
    "        vocab_file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4a639885-b4ea-4bac-849b-df26783a6e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing:  chromium-corpus\n",
      "processing:  conversations-gone-awry-cmv-corpus\n",
      "processing:  conversations-gone-awry-corpus\n",
      "processing:  deli-corpus\n",
      "processing:  diplomacy-corpus\n",
      "processing:  friends-corpus\n",
      "processing:  fomc-corpus\n",
      "processing:  fora-corpus\n",
      "processing:  gap-corpus\n",
      "processing:  iq2-corpus\n",
      "processing:  movie-corpus\n",
      "processing:  npr-2p-corpus\n",
      "processing:  parliament-corpus\n",
      "processing:  persuasionforgood-corpus\n",
      "processing:  reddit-coarse-discourse-corpus\n",
      "processing:  reddit-corpus\n",
      "processing:  reddit-corpus-small\n",
      "processing:  spolin-corpus\n",
      "processing:  stack-exchange-politeness-corpus\n",
      "processing:  supreme-corpus\n",
      "processing:  switchboard-corpus\n",
      "processing:  switchboard-processed-corpus\n",
      "processing:  tennis-corpus\n",
      "processing:  wiki-corpus\n",
      "processing:  wiki-politeness-annotated\n",
      "processing:  wikiconv-corpus\n",
      "processing:  wikipedia-politeness-corpus\n",
      "processing:  winning-args-corpus\n",
      "processing:  wiki-articles-for-deletion-corpus\n",
      "processing:  casino-corpus\n",
      "processing:  wiki-sampled-en-corpus\n",
      "processing:  wiki-sampled-zh-corpus\n"
     ]
    }
   ],
   "source": [
    "# copy all raw text into one text\n",
    "vocab = defaultdict(int)\n",
    "with open(raw_text_file, 'w') as raw_text_f:\n",
    "    for corpus_name in corpus_names:\n",
    "        input_file = f\"datasets/convokit/convokit-{corpus_name}.txt\"\n",
    "        if not os.path.exists(input_file):\n",
    "                print('missing', input_file)\n",
    "                continue\n",
    "        print('processing: ', corpus_name)\n",
    "        with open(input_file, 'r') as infile:\n",
    "            for line in infile:\n",
    "                for item in line.split(' '):\n",
    "                        vocab[item] += 1\n",
    "                raw_text_f.write(line + '\\n')\n",
    "\n",
    "sorted_vocab = sorted(vocab.items(), key=lambda item: item[1], reverse=True)\n",
    "with open(raw_text_vocab, \"w\") as vocab_file:\n",
    "    for word,count in sorted_vocab:\n",
    "        json.dump({word:count}, vocab_file)\n",
    "        vocab_file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9cbdf675-a557-4f19-8ca9-04da712db0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5400120\n",
      "2325084\n",
      "1237689\n",
      "986397\n",
      "781588\n",
      "684273\n",
      "273032\n"
     ]
    }
   ],
   "source": [
    "print(len(sorted_vocab))\n",
    "print(len(sorted_vocab) - len([_ for _ in sorted_vocab if _[1] == 1]))\n",
    "print(len(sorted_vocab) - len([_ for _ in sorted_vocab if _[1] <= 2]))\n",
    "print(len(sorted_vocab) - len([_ for _ in sorted_vocab if _[1] <= 3]))\n",
    "print(len(sorted_vocab) - len([_ for _ in sorted_vocab if _[1] <= 4]))\n",
    "print(len(sorted_vocab) - len([_ for _ in sorted_vocab if _[1] <= 5]))\n",
    "print(len(sorted_vocab) - len([_ for _ in sorted_vocab if _[1] <= 20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "46d1da46-e262-43c7-9057-10430dd48a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading /Users/baojianzhou/.convokit/model_3_10_prec.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading /Users/baojianzhou/.convokit/model_3_20_prec.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading /Users/baojianzhou/.convokit/model_3_30_prec.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading /Users/baojianzhou/.convokit/model_3_40_prec.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading /Users/baojianzhou/.convokit/model_3_50_prec.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading /Users/baojianzhou/.convokit/model_3_60_prec.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading /Users/baojianzhou/.convokit/model_3_70_prec.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading /Users/baojianzhou/.convokit/model_3_80_prec.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading /Users/baojianzhou/.convokit/model_3_90_prec.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading /Users/baojianzhou/.convokit/model_3_100_prec.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "import kenlm\n",
    "order = 3 \n",
    "list_models = []\n",
    "# for prec in [10,20,30,40,50,60,70,80,90,100]:\n",
    "for prec in [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]:\n",
    "    list_models.append(kenlm.Model(f'/Users/baojianzhou/.convokit/model_{order}_{prec}_prec.arpa'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d45f957d-f546-4d9c-b77c-47bec87dd424",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_perplexity(test_sents, model):\n",
    "    tokens = 0\n",
    "    sum_log10_prob = 0.\n",
    "    for sent in test_sents:\n",
    "        log10_prob = model.score(sent, bos=True, eos=True)\n",
    "        tokens += len(sent.split())  + 1 # 1 means </s>\n",
    "        sum_log10_prob += log10_prob\n",
    "    # Calculate the perplexity: 10 ** (-log10_prob / N)\n",
    "    perplexity = 10.0** (-sum_log10_prob/tokens)\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ef874e55-eea7-4ef9-9c62-1d96cec95744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "442.41831186434985\n",
      "162.60105489495086\n",
      "127.05851816030182\n",
      "108.40705505223752\n",
      "99.94808224645347\n",
      "89.69837431876698\n",
      "85.84045806974976\n",
      "69.08049082082734\n",
      "65.41434890622038\n",
      "64.59703405663764\n"
     ]
    }
   ],
   "source": [
    "perplexity_3 = []\n",
    "with open('datasets/convokit/convokit-all-test.txt', 'r') as f:\n",
    "    test_sents = f.readlines()\n",
    "for model in list_models:\n",
    "    prep = calculate_perplexity(test_sents, model)\n",
    "    print(prep)\n",
    "    perplexity_3.append(prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9aee9637-bff7-48c2-b1a4-41f2fcc2e384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "527.049204175791\n",
      "221.13800965967647\n",
      "189.87998207110002\n",
      "177.69569311468467\n",
      "175.0490856053404\n",
      "168.36438360200867\n",
      "163.88783162968556\n",
      "140.6780406945371\n",
      "134.2935780548883\n",
      "133.22550438199124\n"
     ]
    }
   ],
   "source": [
    "perplexity_2 = []\n",
    "with open('datasets/convokit/convokit-all-test.txt', 'r') as f:\n",
    "    test_sents = f.readlines()\n",
    "for model in list_models:\n",
    "    prep = calculate_perplexity(test_sents, model)\n",
    "    print(prep)\n",
    "    perplexity_2.append(prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eba57f3-edc0-4737-8e25-699e697da8e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(1, 11), perplexity, marker=\"D\", color=\"green\", label=\"Bigram\")\n",
    "plt.plot(np.arange(1, 11) / 10, perplexity_3, marker=\"D\", color=\"blue\", label=\"Trigram\")\n",
    "plt.xlabel('Procentage of tokens')\n",
    "plt.ylabel('Perplexity')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f0dfa5-4954-41dc-add6-bb739bd9466e",
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexity = []\n",
    "with open('convokit-reddit-coarse-discourse-corpus-test.txt', 'r') as f:\n",
    "    test_sents = f.readlines()\n",
    "model_names = ['2-gram', '3-gram', '4-gram', '5-gram']\n",
    "for model, model_name in zip([gram_2_model, gram_3_model, gram_4_model, gram_5_model], model_names):\n",
    "    print(model_name, calculate_perplexity(test_sents, model))\n",
    "    perplexity.append(calculate_perplexity(test_sents, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7702e037-8487-4dbf-a603-5d3ffc299c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "less_freq_vocab = {_[0]:'UNK' for _ in sorted_vocab if _[1] <=5 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4cf2008b-7bbb-4cb6-b0c7-6492c258d91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing:  chromium-corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4504774it [00:09, 464951.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing:  conversations-gone-awry-cmv-corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "258619it [00:00, 320270.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing:  conversations-gone-awry-corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "118269it [00:00, 288923.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing:  deli-corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14372it [00:00, 624164.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing:  diplomacy-corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30503it [00:00, 440876.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing:  friends-corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "105747it [00:00, 778924.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing:  fomc-corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "465026it [00:01, 299785.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing:  fora-corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "465026it [00:01, 300730.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing:  gap-corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8218it [00:00, 800743.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing:  iq2-corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "124834it [00:00, 365550.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing:  movie-corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "510477it [00:00, 724839.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing:  npr-2p-corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1177187it [00:03, 369452.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing:  parliament-corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1352322it [00:05, 248230.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing:  persuasionforgood-corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "37116it [00:00, 549403.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing:  reddit-coarse-discourse-corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "355570it [00:00, 369886.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing:  reddit-corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5825131it [00:15, 373871.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing:  reddit-corpus-small\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5825131it [00:15, 381727.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing:  spolin-corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "366651it [00:00, 619115.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing:  stack-exchange-politeness-corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13044it [00:00, 435704.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing:  supreme-corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3973399it [00:12, 326408.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing:  switchboard-corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "164508it [00:00, 460488.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing:  switchboard-processed-corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "107610it [00:00, 345425.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing:  tennis-corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "619334it [00:01, 492314.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing:  wiki-corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "619334it [00:01, 497104.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing:  wiki-politeness-annotated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8655it [00:00, 392769.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing:  wikiconv-corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8655it [00:00, 406468.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing:  wikipedia-politeness-corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8655it [00:00, 398481.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing:  winning-args-corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1599112it [00:04, 320699.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing:  wiki-articles-for-deletion-corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8125052it [00:23, 349238.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing:  casino-corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25613it [00:00, 568039.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing:  wiki-sampled-en-corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "77576it [00:00, 318307.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing:  wiki-sampled-zh-corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13600it [00:00, 286261.82it/s]\n"
     ]
    }
   ],
   "source": [
    "raw_text_file_trim = 'datasets/convokit/convokit-all-raw-text-trim.txt'\n",
    "with open(raw_text_file_trim, 'w') as raw_text_f:\n",
    "    for corpus_name in corpus_names:\n",
    "        input_file = f\"datasets/convokit/convokit-{corpus_name}.txt\"\n",
    "        if not os.path.exists(input_file):\n",
    "            print('missing', input_file)\n",
    "            continue\n",
    "        print('processing: ', corpus_name)\n",
    "        with open(input_file, 'r') as infile:\n",
    "            for line in tqdm(infile):\n",
    "                trimed = []\n",
    "                for item in line.split(' '):\n",
    "                    if item in less_freq_vocab:\n",
    "                        trimed.append(less_freq_vocab[item])\n",
    "                    else:\n",
    "                        trimed.append(item)\n",
    "                raw_text_f.write(\" \".join(trimed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447ad371-9c07-456f-933a-b6025e106952",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "print(string.punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4fe634d3-2bf6-4625-acd4-ed091b783f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35211774it [23:55, 24526.60it/s]\n"
     ]
    }
   ],
   "source": [
    "# copy all raw text into one text\n",
    "raw_text_toknenized = 'datasets/convokit/convokit-all-raw-text-tokenized.txt'\n",
    "with open('datasets/convokit/convokit-all-raw-text-trim.txt', 'r') as raw_text_f:\n",
    "    texts = raw_text_f.readlines()\n",
    "    docs = nlp.tokenizer.pipe(texts)\n",
    "    count = 0\n",
    "    with open(raw_text_toknenized, 'w') as raw_text_ff:\n",
    "        for doc in tqdm(docs):\n",
    "            cleaned_tokens = [token.text if token.is_alpha or token.is_punct or token.is_digit else ' ' for token in doc]\n",
    "            cleaned_text = re.sub(r'[^\\w\\s.,!?;]', ' ', ' '.join(cleaned_tokens))\n",
    "            raw_text_ff.write(\" \".join(cleaned_text.split()) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0a501902-5e54-4191-82de-d977269f1c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35211774it [01:15, 468938.26it/s]\n"
     ]
    }
   ],
   "source": [
    "vocab = defaultdict(int)\n",
    "with open('datasets/convokit/convokit-all-raw-text-tokenized.txt', 'r') as infile:\n",
    "    for line in tqdm(infile):\n",
    "        for item in line.strip().split(' '):\n",
    "            vocab[item] += 1\n",
    "sorted_vocab = sorted(vocab.items(), key=lambda item: item[1], reverse=True)\n",
    "with open(raw_text_vocab_tokenized, \"w\") as vocab_file:\n",
    "    for word, count in sorted_vocab:\n",
    "        json.dump({word:count}, vocab_file)\n",
    "        vocab_file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a35c542b-6a6a-42a5-a4e5-4dec63e19daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "less_freq_vocab = {_[0]:\"UNK\" for _ in sorted_vocab if _[1] <=20 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8cc45f37-5574-4397-815c-33dfe45a6bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223611\n",
      "214033\n",
      "205764\n",
      "203813\n",
      "201653\n",
      "200465\n",
      "99368\n"
     ]
    }
   ],
   "source": [
    "print(len(sorted_vocab))\n",
    "print(len(sorted_vocab) - len([_ for _ in sorted_vocab if _[1] == 1]))\n",
    "print(len(sorted_vocab) - len([_ for _ in sorted_vocab if _[1] <= 2]))\n",
    "print(len(sorted_vocab) - len([_ for _ in sorted_vocab if _[1] <= 3]))\n",
    "print(len(sorted_vocab) - len([_ for _ in sorted_vocab if _[1] <= 4]))\n",
    "print(len(sorted_vocab) - len([_ for _ in sorted_vocab if _[1] <= 5]))\n",
    "print(len(sorted_vocab) - len([_ for _ in sorted_vocab if _[1] <= 20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3d4ca00b-b4ea-4298-af81-3984c9b9b1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "49it [00:00, 16355.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['can', 'you', 'stick', 'this', 'flag', 'up', 'in', 'the', 'group', 'of', 'UNK', 'above', '?']\n",
      "can you stick this flag up in the group of UNK above ?\n",
      "\n",
      "0 can you stick this flag up in the group of UNK above ?\n",
      "\n",
      "['careful', ',', 'your', 'files', 'are', 'out', 'of', 'sync', '.']\n",
      "careful , your files are out of sync .\n",
      "\n",
      "['run', 'scons', 'twice', 'again', '.']\n",
      "run scons twice again .\n",
      "\n",
      "['i', 'would', 'love', 'to', 'see', 'this', 'function', 'as', 'minimal', 'as', 'possible', '.']\n",
      "i would love to see this function as minimal as possible .\n",
      "\n",
      "['can', 'UNK', 'takes', 'UNK', 'as', 'an', 'argument', 'to', 'UNK', 'to', 'make', 'calling', 'it', 'even', 'simpler', '.']\n",
      "can UNK takes UNK as an argument to UNK to make calling it even simpler .\n",
      "\n",
      "['and', 'can', 'it', 'call', 'UNK', 'directly', '?']\n",
      "and can it call UNK directly ?\n",
      "\n",
      "['that', 'way', ',', 'we', 'can', 'change', 'UNK', 'without', 'updating', 'gcl', ',', 'which', 'might', 'live', 'on', 'a', 'different', 'repository', '.']\n",
      "that way , we can change UNK without updating gcl , which might live on a different repository .\n",
      "\n",
      "['is', 'this', 'function', 'needed', ',', 'is', 'this', 'only', 'called', 'by', 'UNKlgtm', ',', 'but', 'i', 'think', 'it', 'more', 'consistent', 'with', 'the', 'rest', 'of', 'the', 'code', 'to', 'not', 'add', 'the', 'extra', 'brackets']\n",
      "is this function needed , is this only called by UNKlgtm , but i think it more consistent with the rest of the code to not add the extra brackets\n",
      "\n",
      "['just', 'curious', 'in', 'general', 'we', 'should', 'include', 'the', 'system', 'headers', 'before', 'our', 'own', 'headers', '.']\n",
      "just curious in general we should include the system headers before our own headers .\n",
      "\n",
      "['but', 'we', 'need', 'to', 'make', 'an', 'exception', 'to', 'get', 'the', 'definition', 'of', 'the', 'macro', '.']\n",
      "but we need to make an exception to get the definition of the macro .\n",
      "\n",
      "['is', 'the', 'header', 'that', 'defines', 'UNKor', 'should', 'we', 'use', 'a', 'smaller', 'header', 'such', 'as', 'UNKwe', 'should', 'return', 'false', 'if', 'this', 'is', 'false', '.']\n",
      "is the header that defines UNKor should we use a smaller header such as UNKwe should return false if this is false .\n",
      "\n",
      "['otherwise', 'it', 'a', 'buffer', 'overflow', '.']\n",
      "otherwise it a buffer overflow .\n",
      "\n",
      "['would', 'notreached', 'be', 'better', '?']\n",
      "would notreached be better ?\n",
      "\n",
      "['i', 'not', 'sure', 'if', 'we', 'need', 'to', 'do', 'here', '.']\n",
      "i not sure if we need to do here .\n",
      "\n",
      "['it', 'be', 'useful', 'only', 'if', 'is', '0', '.']\n",
      "it be useful only if is 0 .\n",
      "\n",
      "['let', 'replace', 'this', 'block', 'comment', 'with', 'something', 'like', 'this', 'this', 'code', 'does', 'work', 'on', 'because', 'UNK', 'and', 'UNK', 'are', 'not', 'supported', 'on', 'windows', '2000', '.']\n",
      "let replace this block comment with something like this this code does work on because UNK and UNK are not supported on windows 2000 .\n",
      "\n",
      "['UNK', 'allows', 'the', 'import', 'of', 'an', 'unencrypted', 'key', '.']\n",
      "UNK allows the import of an unencrypted key .\n",
      "\n",
      "['on', 'we', 'need', 'to', 'use', 'a', 'cumbersome', 'UNK', 'key', 'procedure', 'UNK', 'allows', 'keys', 'longer', 'than', '16', 'bytes', '.']\n",
      "on we need to use a cumbersome UNK key procedure UNK allows keys longer than 16 bytes .\n",
      "\n",
      "['i', 'will', 'close', 'bug']\n",
      "i will close bug\n",
      "\n",
      "['we', 'should', 'take', 'care', 'of', 'this', 'todo', 'now', '.']\n",
      "we should take care of this todo now .\n",
      "\n",
      "['i', 'see', 'what', 'needs', 'to', 'be', 'done', 'here', '.']\n",
      "i see what needs to be done here .\n",
      "\n",
      "['nit', 'msdn', 'example', 'code', 'passes', '0', 'instead', 'of', 'null', 'here', 'i', 'believe', 'it', 'because', 'UNK', 'is', 'not', 'a', 'pointer', '.']\n",
      "nit msdn example code passes 0 instead of null here i believe it because UNK is not a pointer .\n",
      "\n",
      "['it', 'is', 'defined', 'as', 'UNKnit', 'your', 'spacing', 'looks', 'off', 'here', '.']\n",
      "it is defined as UNKnit your spacing looks off here .\n",
      "\n",
      "['is', 'it', 'possible', 'you', 'using', 'a', 'tab', '?']\n",
      "is it possible you using a tab ?\n",
      "\n",
      "['i', 'think', 'it', 'would', 'be', 'easier', 'for', 'delegates', 'if', 'showcontextmenu', 'returned', 'a', 'boolean', 'indicating', 'whether', 'it', 'has', 'a', 'submenu', '.']\n",
      "i think it would be easier for delegates if showcontextmenu returned a boolean indicating whether it has a submenu .\n",
      "\n",
      "['that', 'way', 'there', 'is', 'yet', 'another', 'UNK', 'method', '.']\n",
      "that way there is yet another UNK method .\n",
      "\n",
      "['if', 'showcontextmenu', 'returned', 'false', 'then', 'accept', 'it', '.']\n",
      "if showcontextmenu returned false then accept it .\n",
      "\n",
      "['done', '.']\n",
      "done .\n",
      "\n",
      "['nit', 'same', 'nit', 'as', 'earlier', ',', 'your', 'spacing', 'looks', 'off', '.']\n",
      "nit same nit as earlier , your spacing looks off .\n",
      "\n",
      "['also', ',', 'no', 'space', 'after', 'the', 'openning', 'of', 'the', 'if', 'and', 'closing', ',', 'eg', 'if', 'UNK', '...']\n",
      "also , no space after the openning of the if and closing , eg if UNK ...\n",
      "\n",
      "['it', 'looks', 'like', 'you', 'removed', 'code', 'to', 'show', 'a', 'context', 'menu', 'on', 'menu', 'items', '.']\n",
      "it looks like you removed code to show a context menu on menu items .\n",
      "\n",
      "['this', 'is', 'used', 'for', 'the', 'folder', 'submenus', 'in', 'the', 'bookmark', 'bar', '.']\n",
      "this is used for the folder submenus in the bookmark bar .\n",
      "\n",
      "['is', 'this', 'intentional', '?']\n",
      "is this intentional ?\n",
      "\n",
      "['i', 'do', 'think', 'we', 'want', 'to', 'do', 'this', '.']\n",
      "i do think we want to do this .\n",
      "\n",
      "['are', 'you', 'sure', 'this', 'is', 'the', 'right', 'filename', '?']\n",
      "are you sure this is the right filename ?\n",
      "\n",
      "['i', 'thought', 'it', 'was', 'UNKUNK', 'sounds', 'about', 'right', '.']\n",
      "i thought it was UNKUNK sounds about right .\n",
      "\n",
      "['there', 'are', 'some', 'UNK', 'functions', 'that', 'can', 'be', 'used', 'to', 'pull', 'things', 'off', 'the', 'command', 'line', 'with', 'automatic', 'error', 'checking', 'and', 'help', 'text', 'and', 'the', 'like', '.']\n",
      "there are some UNK functions that can be used to pull things off the command line with automatic error checking and help text and the like .\n",
      "\n",
      "['what', 'you', 'have', 'is', 'fine', ',', 'but', 'if', 'you', 'want', 'to', 'start', 'doing', 'things', 'in', 'the', 'future', 'like', 'restricting', 'mode', 'to', 'a', 'set', 'of', 'known', ',', 'legal', 'input', 'values', ',', 'the', 'code', 'already', 'exists', 'for', 'that', 'and', 'you', 'do', 'need', 'to', 'invent', 'it', '.']\n",
      "what you have is fine , but if you want to start doing things in the future like restricting mode to a set of known , legal input values , the code already exists for that and you do need to invent it .\n",
      "\n",
      "['thanks', 'for', 'the', 'tip', '.']\n",
      "thanks for the tip .\n",
      "\n",
      "['i', 'think', 'i', 'add', 'that', 'in', 'a', 'future', 'revision', 'so', 'you', 'do', 'have', 'to', 'keep', 'reviewing', 'changes', '.']\n",
      "i think i add that in a future revision so you do have to keep reviewing changes .\n",
      "\n",
      "['you', 'can', 'get', 'the', 'string', 'expansion', 'directly', 'using', 'UNK', 'UNK', 'sadly', ',', 'that', 'expands', 'to', 'UNK']\n",
      "you can get the string expansion directly using UNK UNK sadly , that expands to UNK\n",
      "\n",
      "['there', 'a', 'number', 'of', 'places', 'where', 'i', 'want', 'to', 'use', 'these', 'variables', ',', 'but', 'without', 'the', 'UNK', 'prefix', '.']\n",
      "there a number of places where i want to use these variables , but without the UNK prefix .\n",
      "\n",
      "['so', 'far', ',', 'i', 'had', 'no', 'luck', 'with', 'experiments', 'UNK', 'is', 'close', ',', 'but', 'i', 'want', 'an', 'abspath', 'UNK', 'gives', 'the', 'abspath', 'to', 'the', 'UNK', 'UNK', 'gives', 'the', 'build', 'dir', 'there', 'is', 'no', 'UNK', 'or', 'UNK', 'or', 'any', 'such', 'thing', 'this', 'is', 'one', 'of', 'the', 'more', 'common', 'issues', 'i', 'had', 'with', 'writing', 'scons', 'scripts', 'mostly', 'when', 'writing', 'my', 'own', 'UNK']\n",
      "so far , i had no luck with experiments UNK is close , but i want an abspath UNK gives the abspath to the UNK UNK gives the build dir there is no UNK or UNK or any such thing this is one of the more common issues i had with writing scons scripts mostly when writing my own UNK\n",
      "\n",
      "['i', 'ca', 'help', 'but', 'feel', 'there', 'must', 'be', 'an', 'easier', 'way', 'to', 'get', 'the', 'src', 'path', 'from', 'the', 'build', 'output', 'path', '.']\n",
      "i ca help but feel there must be an easier way to get the src path from the build output path .\n",
      "\n",
      "['good', 'start', ';', 'nothing', 'obviously', 'wrong', 'off', 'the', 'top', 'of', 'my', 'head', '.']\n",
      "good start ; nothing obviously wrong off the top of my head .\n",
      "\n",
      "['swing', 'by', 'if', 'you', 'want', 'some', 'additional', 'eyes', 'debugging', '.']\n",
      "swing by if you want some additional eyes debugging .\n",
      "\n",
      "['there', 'are', 'a', 'few', 'problems', 'with', 'writing', 'a', 'scanner', 'for', 'this', '.']\n",
      "there are a few problems with writing a scanner for this .\n",
      "\n",
      "['1', '.', 'path', 'passed', 'into', 'UNK', 'is', 'empty', '.']\n",
      "1 . path passed into UNK is empty .\n",
      "\n",
      "['i', 'think', 'i', 'can', 'use', 'UNK', 'UNK', 'passed', 'to', 'scanner', ',', 'but', 'i', 'have', 'had', 'much', 'luck', '.']\n",
      "i think i can use UNK UNK passed to scanner , but i have had much luck .\n",
      "\n",
      "['2', '.', 'more', 'importantly', ',', 'these', 'UNK', 'files', 'depend', 'on', 'generated', 'files', 'that', 'may', 'not', 'exist', 'yet', '.']\n",
      "2 . more importantly , these UNK files depend on generated files that may not exist yet .\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_file = 'datasets/convokit/convokit-all-train.txt'\n",
    "valid_file = 'datasets/convokit/convokit-all-valid.txt'\n",
    "test_file = 'datasets/convokit/convokit-all-test.txt'\n",
    "\n",
    "random.seed(17)\n",
    "if not os.path.exists('datasets/convokit/convokit-all-raw-text-tokenized.txt'):\n",
    "    print('missing', 'datasets/convokit/convokit-all-raw-text-tokenized.txt')\n",
    "vocab = defaultdict(int)\n",
    "count = 0\n",
    "with open(train_file, 'w') as train_out, open(valid_file, 'w') as valid_out, open(test_file, 'w') as test_out:\n",
    "    with open('datasets/convokit/convokit-all-raw-text-tokenized.txt', 'r') as infile:\n",
    "        for ind, line in tqdm(enumerate(infile)):\n",
    "            effective_tokens = []\n",
    "            for item in line.strip().split(' '):\n",
    "                if item in less_freq_vocab:\n",
    "                    effective_tokens.append(less_freq_vocab[item])\n",
    "                else:\n",
    "                    effective_tokens.append(item)\n",
    "            print(effective_tokens)\n",
    "            print(\" \".join(effective_tokens) + '\\n')\n",
    "            count += 1\n",
    "            if count == 50:\n",
    "                break\n",
    "            rand = random.random()  # Generate a random number between 0 and 1\n",
    "            if rand < 0.98:  # 98% probability for train\n",
    "                train_out.write(\" \".join(effective_tokens) + '\\n')\n",
    "                for item in line.split():\n",
    "                    vocab[item] += 1\n",
    "            elif rand < 0.99:  # 1% probability for valid\n",
    "                valid_out.write(\" \".join(effective_tokens) + '\\n')\n",
    "            else:  # 1% probability for test\n",
    "                test_out.write(\" \".join(effective_tokens) + '\\n')\n",
    "            if ind % 2000 == 0:\n",
    "                print(ind, line)\n",
    "sorted_vocab = sorted(vocab.items(), key=lambda item: item[1], reverse=True)\n",
    "with open(\"datasets/convokit/convokit-all-vocab.json\", \"w\") as vocab_file:\n",
    "    for word,count in sorted_vocab:\n",
    "        json.dump({word:count}, vocab_file)\n",
    "        vocab_file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "16e44860-cdfa-4d84-9512-543d2c2e3aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "719768it [07:05, 1692.58it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(raw_text_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m infile:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m tqdm(infile):\n\u001b[0;32m----> 8\u001b[0m         tokens \u001b[38;5;241m=\u001b[39m \u001b[43mclean_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m tokens:\n\u001b[1;32m     10\u001b[0m             vocab[item] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[0;32mIn[39], line 2\u001b[0m, in \u001b[0;36mclean_text\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclean_text\u001b[39m(text):\n\u001b[0;32m----> 2\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43mnlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     cleaned_tokens \u001b[38;5;241m=\u001b[39m [token\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;28;01mif\u001b[39;00m token\u001b[38;5;241m.\u001b[39mis_alpha \u001b[38;5;129;01mor\u001b[39;00m token\u001b[38;5;241m.\u001b[39mis_punct \u001b[38;5;129;01mor\u001b[39;00m token\u001b[38;5;241m.\u001b[39mis_digit \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m doc]\n\u001b[1;32m      4\u001b[0m     cleaned_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(cleaned_tokens)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp-25/lib/python3.10/site-packages/spacy/language.py:1052\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m   1050\u001b[0m     error_handler \u001b[38;5;241m=\u001b[39m proc\u001b[38;5;241m.\u001b[39mget_error_handler()\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1052\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43mproc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcomponent_cfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1054\u001b[0m     \u001b[38;5;66;03m# This typically happens if a component is not initialized\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE109\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp-25/lib/python3.10/site-packages/spacy/pipeline/trainable_pipe.pyx:52\u001b[0m, in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp-25/lib/python3.10/site-packages/spacy/pipeline/tok2vec.py:126\u001b[0m, in \u001b[0;36mTok2Vec.predict\u001b[0;34m(self, docs)\u001b[0m\n\u001b[1;32m    124\u001b[0m     width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mget_dim(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnO\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39malloc((\u001b[38;5;241m0\u001b[39m, width)) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs]\n\u001b[0;32m--> 126\u001b[0m tokvecs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tokvecs\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp-25/lib/python3.10/site-packages/thinc/model.py:334\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m OutT:\n\u001b[1;32m    331\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function with `is_train=False`, and return\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;124;03m    only the output, instead of the `(output, callback)` tuple.\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp-25/lib/python3.10/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp-25/lib/python3.10/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp-25/lib/python3.10/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp-25/lib/python3.10/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp-25/lib/python3.10/site-packages/thinc/layers/with_array.py:36\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, Xseq, is_train)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m     33\u001b[0m     model: Model[SeqT, SeqT], Xseq: SeqT, is_train: \u001b[38;5;28mbool\u001b[39m\n\u001b[1;32m     34\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[SeqT, Callable]:\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(Xseq, Ragged):\n\u001b[0;32m---> 36\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m cast(Tuple[SeqT, Callable], \u001b[43m_ragged_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXseq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(Xseq, Padded):\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m cast(Tuple[SeqT, Callable], _padded_forward(model, Xseq, is_train))\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp-25/lib/python3.10/site-packages/thinc/layers/with_array.py:91\u001b[0m, in \u001b[0;36m_ragged_forward\u001b[0;34m(model, Xr, is_train)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_ragged_forward\u001b[39m(\n\u001b[1;32m     88\u001b[0m     model: Model[SeqT, SeqT], Xr: Ragged, is_train: \u001b[38;5;28mbool\u001b[39m\n\u001b[1;32m     89\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Ragged, Callable]:\n\u001b[1;32m     90\u001b[0m     layer: Model[ArrayXd, ArrayXd] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 91\u001b[0m     Y, get_dX \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataXd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackprop\u001b[39m(dYr: Ragged) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Ragged:\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m Ragged(get_dX(dYr\u001b[38;5;241m.\u001b[39mdataXd), dYr\u001b[38;5;241m.\u001b[39mlengths)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp-25/lib/python3.10/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp-25/lib/python3.10/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp-25/lib/python3.10/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp-25/lib/python3.10/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp-25/lib/python3.10/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp-25/lib/python3.10/site-packages/thinc/layers/layernorm.py:24\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(model: Model[InT, InT], X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[InT, Callable]:\n\u001b[0;32m---> 24\u001b[0m     N, mu, var \u001b[38;5;241m=\u001b[39m \u001b[43m_get_moments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     Xhat \u001b[38;5;241m=\u001b[39m (X \u001b[38;5;241m-\u001b[39m mu) \u001b[38;5;241m*\u001b[39m var \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2.0\u001b[39m)\n\u001b[1;32m     26\u001b[0m     Y, backprop_rescale \u001b[38;5;241m=\u001b[39m _begin_update_scale_shift(model, Xhat)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp-25/lib/python3.10/site-packages/thinc/layers/layernorm.py:76\u001b[0m, in \u001b[0;36m_get_moments\u001b[0;34m(ops, X)\u001b[0m\n\u001b[1;32m     74\u001b[0m mu: Floats2d \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     75\u001b[0m var: Floats2d \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mvar(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-08\u001b[39m\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(Floats2d, \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray_f\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m), mu, var\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp-25/lib/python3.10/site-packages/thinc/backends/ops.py:705\u001b[0m, in \u001b[0;36mOps.asarray_f\u001b[0;34m(self, data, dtype)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21masarray_f\u001b[39m(\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    701\u001b[0m     data: Union[FloatsXd, Sequence[Any]],\n\u001b[1;32m    702\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m    703\u001b[0m     dtype: Optional[DTypes] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    704\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m FloatsXd:\n\u001b[0;32m--> 705\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(FloatsXd, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp-25/lib/python3.10/site-packages/thinc/backends/numpy_ops.pyx:74\u001b[0m, in \u001b[0;36mthinc.backends.numpy_ops.NumpyOps.asarray\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# copy all raw text into one text\n",
    "raw_text_toknenized = 'datasets/convokit/convokit-all-raw-text-tokenized.txt'\n",
    "raw_text_vocab_tokenized = 'datasets/convokit/convokit-all-raw-vocab.txt'\n",
    "vocab = defaultdict(int)\n",
    "with open(raw_text_toknenized, 'w') as raw_text_f:\n",
    "    texts = raw_text_f.readlines()\n",
    "    docs = nlp.tokenizer.pipe(texts)\n",
    "    with open(raw_text_file, 'r') as infile:\n",
    "        for line in tqdm(infile):\n",
    "            tokens = clean_text(line)\n",
    "            for item in tokens:\n",
    "                vocab[item] += 1\n",
    "            raw_text_f.write(\" \".join(tokens) + '\\n')\n",
    "sorted_vocab = sorted(vocab.items(), key=lambda item: item[1], reverse=True)\n",
    "with open(raw_text_vocab_tokenized, \"w\") as vocab_file:\n",
    "    for word,count in sorted_vocab:\n",
    "        json.dump({word:count}, vocab_file)\n",
    "        vocab_file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "19021154-4eb7-4d40-a4a6-194fcb03e1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "less_freq_vocab = {_:'UNK' for _ in sorted_vocab if _[1] <=5 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409a134a-df9b-4136-9e6d-5fa2cbf39b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(sorted_vocab) - len([_ for _ in sorted_vocab if _[1] <= 5]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
